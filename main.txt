
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from timm import create_model
import pandas as pd
from PIL import Image
import os
from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Set dataset path
data_path = "/kaggle/input/chest-xray-pneumonia/chest_xray"

# Data Augmentation and Normalization
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# Custom Dataset
class ChestXrayDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.classes = ['NORMAL', 'PNEUMONIA']
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}
        self.images = self._load_images()

    def _load_images(self):
        images = []
        for class_name in self.classes:
            class_dir = os.path.join(self.root_dir, class_name)
            if not os.path.exists(class_dir):
                print(f"Warning: Directory {class_dir} does not exist")
                continue

            for img_name in os.listdir(class_dir):
                if img_name.endswith(('.jpeg', '.jpg', '.png', '.JPG', '.JPEG')):
                    img_path = os.path.join(class_dir, img_name)
                    images.append((img_path, self.class_to_idx[class_name]))
        return images

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path, label = self.images[idx]
        try:
            image = Image.open(img_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
            return image, label
        except Exception as e:
            print(f"Error loading image {img_path}: {e}")
            # Return a placeholder image
            return torch.zeros(3, 224, 224), label

# Create datasets
train_dataset = ChestXrayDataset(os.path.join(data_path, 'train'), transform=train_transform)
val_dataset = ChestXrayDataset(os.path.join(data_path, 'val'), transform=val_transform)
test_dataset = ChestXrayDataset(os.path.join(data_path, 'test'), transform=val_transform)

# Check dataset sizes and class distribution
print(f"Training samples: {len(train_dataset)}")
print(f"Validation samples: {len(val_dataset)}")
print(f"Test samples: {len(test_dataset)}")

# Since validation set is very small (only 16 samples), let's use part of training for validation
# We'll split the training data into train/val
from sklearn.model_selection import train_test_split

# Create indices for train/val split
train_indices, val_indices = train_test_split(
    range(len(train_dataset)),
    test_size=0.2,
    random_state=42,
    stratify=[label for _, label in train_dataset.images]
)

# Create subset datasets
from torch.utils.data import Subset
train_subset = Subset(train_dataset, train_indices)
val_subset = Subset(train_dataset, val_indices)

print(f"New training samples: {len(train_subset)}")
print(f"New validation samples: {len(val_subset)}")

# Create data loaders
train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=2)
val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)

# Create Swin Transformer model
model = create_model('swin_tiny_patch4_window7_224',
                     pretrained=True,
                     num_classes=2)  # Normal and Pneumonia
model = model.to(device)

# Training setup
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)

# Training function
def train_model(model, train_loader, val_loader, epochs=10):
    train_losses = []
    val_losses = []
    val_accuracies = []

    best_acc = 0.0
    best_model_wts = None

    for epoch in range(epochs):
        # Training phase
        model.train()
        running_loss = 0.0

        for batch_idx, (images, labels) in enumerate(train_loader):
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * images.size(0)

            if batch_idx % 50 == 0:
                print(f'Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')

        epoch_loss = running_loss / len(train_loader.dataset)
        train_losses.append(epoch_loss)

        # Validation phase
        model.eval()
        running_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)

                running_loss += loss.item() * images.size(0)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        val_loss = running_loss / len(val_loader.dataset)
        val_acc = 100 * correct / total

        val_losses.append(val_loss)
        val_accuracies.append(val_acc)

        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')

        # Update learning rate
        scheduler.step(val_acc)

        # Save best model
        if val_acc > best_acc:
            best_acc = val_acc
            best_model_wts = model.state_dict().copy()
            torch.save(model.state_dict(), 'best_model.pth')
            print(f'New best model saved with accuracy: {best_acc:.2f}%')

    # Load best model weights
    model.load_state_dict(best_model_wts)

    # Plot training history
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Training Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(val_accuracies, label='Validation Accuracy')
    plt.title('Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy (%)')
    plt.legend()

    plt.tight_layout()
    plt.show()

    return train_losses, val_losses, val_accuracies

# Train the model
print("Starting training...")
train_losses, val_losses, val_accuracies = train_model(model, train_loader, val_loader, epochs=10)

# Evaluation function
def evaluate_model(model, test_loader):
    model.eval()
    all_preds = []
    all_labels = []
    all_probs = []
    running_loss = 0.0

    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            running_loss += loss.item() * images.size(0)

            probs = torch.softmax(outputs, dim=1)
            _, preds = torch.max(outputs, 1)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())

    test_loss = running_loss / len(test_loader.dataset)

    # Calculate metrics
    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average='weighted')
    recall = recall_score(all_labels, all_preds, average='weighted')
    f1 = f1_score(all_labels, all_preds, average='weighted')

    # Classification report
    class_names = ['NORMAL', 'PNEUMONIA']
    print("\nClassification Report:")
    print(classification_report(all_labels, all_preds, target_names=class_names, digits=4))

    # Confusion matrix
    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title('Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.show()

    # Print detailed metrics
    print(f"\nDetailed Metrics:")
    print(f"Test Loss: {test_loss:.6f}")
    print(f"Accuracy: {accuracy:.6f} ({accuracy*100:.4f}%)")
    print(f"Precision: {precision:.6f}")
    print(f"Recall: {recall:.6f}")
    print(f"F1-Score: {f1:.6f}")

    # Calculate class-wise metrics
    cm = confusion_matrix(all_labels, all_preds)
    tn, fp, fn, tp = cm.ravel()

    print(f"\nClass-wise Metrics:")
    print(f"True Positives (TP): {tp}")
    print(f"True Negatives (TN): {tn}")
    print(f"False Positives (FP): {fp}")
    print(f"False Negatives (FN): {fn}")

    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0

    print(f"Sensitivity (Recall for Pneumonia): {sensitivity:.6f}")
    print(f"Specificity (Recall for Normal): {specificity:.6f}")

    return all_preds, all_labels, all_probs, test_loss, accuracy, precision, recall, f1

# Evaluate the model
print("Evaluating model on test set...")
all_preds, all_labels, all_probs, test_loss, accuracy, precision, recall, f1 = evaluate_model(model, test_loader)

# Save the final model
torch.save({
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'test_accuracy': accuracy,
    'test_loss': test_loss
}, 'pneumonia_detection_model_complete.pth')

print("Model saved as 'pneumonia_detection_model_complete.pth'")

# Create a comprehensive results dataframe
results_df = pd.DataFrame({
    'Metric': ['Test Loss', 'Accuracy', 'Precision', 'Recall', 'F1-Score'],
    'Value': [test_loss, accuracy, precision, recall, f1],
    'Percentage': ['-', f'{accuracy*100:.4f}%', f'{precision*100:.4f}%', f'{recall*100:.4f}%', f'{f1*100:.4f}%']
})

print("\n" + "="*50)
print("COMPREHENSIVE RESULTS SUMMARY")
print("="*50)
print(results_df.to_string(index=False))

# Calculate and display additional metrics
cm = confusion_matrix(all_labels, all_preds)
tn, fp, fn, tp = cm.ravel()

additional_metrics = pd.DataFrame({
    'Metric': ['True Positives', 'True Negatives', 'False Positives', 'False Negatives',
               'Sensitivity', 'Specificity', 'Total Samples'],
    'Value': [tp, tn, fp, fn,
              f"{tp/(tp+fn):.4f}" if (tp+fn) > 0 else "0.0000",
              f"{tn/(tn+fp):.4f}" if (tn+fp) > 0 else "0.0000",
              len(all_labels)]
})

print("\nAdditional Metrics:")
print(additional_metrics.to_string(index=False))